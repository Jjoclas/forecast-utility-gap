{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2020-01-01 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2023-07-03 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2023-10-04 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2024-01-12 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2024-04-17 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2024-07-22 to 2025-03-26 for AAPL...\n",
      "Rate limit exceeded. Waiting for 60 seconds...\n",
      "Fetching data from 2024-07-22 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2024-10-24 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2025-02-04 to 2025-03-26 for AAPL...\n",
      "Fetching data from 2025-03-25 to 2025-03-26 for AAPL...\n",
      "No more data available.\n",
      "Saved AAPL_M1.csv\n",
      "Fetched and saved 376540 rows for AAPL.\n",
      "Fetching data from 2020-01-01 to 2025-03-26 for MSFT...\n",
      "Fetching data from 2023-07-19 to 2025-03-26 for MSFT...\n",
      "Rate limit exceeded. Waiting for 60 seconds...\n",
      "Fetching data from 2023-07-19 to 2025-03-26 for MSFT...\n",
      "Fetching data from 2023-11-08 to 2025-03-26 for MSFT...\n",
      "Fetching data from 2024-03-01 to 2025-03-26 for MSFT...\n",
      "Fetching data from 2024-07-01 to 2025-03-26 for MSFT...\n",
      "Fetching data from 2024-10-28 to 2025-03-26 for MSFT...\n",
      "Fetching data from 2025-02-24 to 2025-03-26 for MSFT...\n",
      "Rate limit exceeded. Waiting for 60 seconds...\n",
      "Fetching data from 2025-02-24 to 2025-03-26 for MSFT...\n",
      "Fetching data from 2025-03-25 to 2025-03-26 for MSFT...\n",
      "No more data available.\n",
      "Saved MSFT_M1.csv\n",
      "Fetched and saved 314238 rows for MSFT.\n",
      "Fetching data from 2020-01-01 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2023-06-29 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2023-10-04 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2024-01-12 to 2025-03-26 for AMZN...\n",
      "Rate limit exceeded. Waiting for 60 seconds...\n",
      "Fetching data from 2024-01-12 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2024-04-22 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2024-07-31 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2024-11-05 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2025-02-13 to 2025-03-26 for AMZN...\n",
      "Fetching data from 2025-03-25 to 2025-03-26 for AMZN...\n",
      "Rate limit exceeded. Waiting for 60 seconds...\n",
      "Fetching data from 2025-03-25 to 2025-03-26 for AMZN...\n",
      "No more data available.\n",
      "Saved AMZN_M1.csv\n",
      "Fetched and saved 372786 rows for AMZN.\n",
      "Fetching data from 2020-01-01 to 2025-03-26 for GOOGL...\n",
      "Fetching data from 2023-07-18 to 2025-03-26 for GOOGL...\n",
      "Fetching data from 2023-11-10 to 2025-03-26 for GOOGL...\n",
      "Fetching data from 2024-03-06 to 2025-03-26 for GOOGL...\n",
      "Fetching data from 2024-07-02 to 2025-03-26 for GOOGL...\n",
      "Rate limit exceeded. Waiting for 60 seconds...\n",
      "Fetching data from 2024-07-02 to 2025-03-26 for GOOGL...\n",
      "Fetching data from 2024-10-23 to 2025-03-26 for GOOGL...\n",
      "Fetching data from 2025-02-07 to 2025-03-26 for GOOGL...\n",
      "Fetching data from 2025-03-25 to 2025-03-26 for GOOGL...\n",
      "No more data available.\n",
      "Saved GOOGL_M1.csv\n",
      "Fetched and saved 323725 rows for GOOGL.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "API_KEY = \"\" # Add your API key here\n",
    "\n",
    "# Base URL for Polygon Forex API\n",
    "BASE_URL = \"https://api.polygon.io\"\n",
    "\n",
    "def fetch_paginated_forex_data(pair, multiplier, timespan, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch all forex candlestick data from Polygon API, handling pagination.\n",
    "\n",
    "    :param pair: Forex pair, e.g., 'C:EURUSD', 'C:EURGBP'\n",
    "    :param multiplier: Time multiplier, e.g., 1 for 1-minute\n",
    "    :param timespan: Timespan, e.g., 'minute', 'hour'\n",
    "    :param start_date: Start date in 'YYYY-MM-DD' format\n",
    "    :param end_date: End date in 'YYYY-MM-DD' format\n",
    "    :return: DataFrame with all paginated candlestick data\n",
    "    \"\"\"\n",
    "    final_df = pd.DataFrame()\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date < end_date:\n",
    "        url = f\"{BASE_URL}/v2/aggs/ticker/{pair}/range/{multiplier}/{timespan}/{current_date}/{end_date}\"\n",
    "        params = {\n",
    "            \"adjusted\": \"true\",\n",
    "            \"sort\": \"asc\",\n",
    "            \"limit\": 50000,\n",
    "            \"apiKey\": API_KEY\n",
    "        }\n",
    "\n",
    "        print(f\"Fetching data from {current_date} to {end_date} for {pair}...\")\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json().get(\"results\", [])\n",
    "            if not data:\n",
    "                print(\"No more data available.\")\n",
    "                break\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "            df.rename(columns={\"t\": \"from\", \"o\": \"open\", \"h\": \"max\", \"l\": \"min\", \"c\": \"close\", \"v\": \"volume\"}, inplace=True)\n",
    "            df = df[[\"from\", \"open\", \"max\", \"min\", \"close\", \"volume\"]]\n",
    "            df['at'] = df['from']\n",
    "            df['to'] = df['from']\n",
    "            df['from'] = df['from'] // 1000\n",
    "            df['to'] = df['to'] // 1000\n",
    "\n",
    "            final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "            last_timestamp = df[\"to\"].iloc[-1]\n",
    "            last_current = current_date\n",
    "            current_date = (datetime.fromtimestamp(last_timestamp) + timedelta(minutes=1)).strftime(\"%Y-%m-%d\")\n",
    "            if current_date == last_current:\n",
    "                print(\"No more data available.\")\n",
    "                break\n",
    "        elif response.status_code == 429:\n",
    "            print(\"Rate limit exceeded. Waiting for 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def fetch_data_for_assets(assets, multiplier=1, timespan=\"minute\", start_date=\"2020-01-01\", end_date=None):\n",
    "    \"\"\"\n",
    "    Fetches forex data for a list of assets and saves each dataset immediately.\n",
    "\n",
    "    :param assets: List of asset symbols in Polygon format, e.g., ['C:EURUSD', 'C:EURGBP']\n",
    "    :param multiplier: Time multiplier, e.g., 1 for 1-minute\n",
    "    :param timespan: Timespan, e.g., 'minute', 'hour'\n",
    "    :param start_date: Start date in 'YYYY-MM-DD' format\n",
    "    :param end_date: End date in 'YYYY-MM-DD' format (defaults to today)\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    for asset in assets:\n",
    "        df = fetch_paginated_forex_data(asset, multiplier, timespan, start_date, end_date)\n",
    "        if len(df) > 0:\n",
    "            save_data_to_csv(asset, df)\n",
    "            print(f\"Fetched and saved {len(df)} rows for {asset}.\")\n",
    "\n",
    "def save_data_to_csv(asset, df, timespan=\"M1\"):\n",
    "    \"\"\"\n",
    "    Saves forex data to a CSV file.\n",
    "\n",
    "    :param asset: Asset symbol\n",
    "    :param df: DataFrame containing the asset's data\n",
    "    :param timespan: Timeframe label for filename\n",
    "    \"\"\"\n",
    "    if len(df) != 0:\n",
    "        asset_name = asset.replace(\"C:\", \"\").replace(\":\", \"\")\n",
    "        df.to_csv(f\"{asset_name}_{timespan}.csv\", index=False)\n",
    "        print(f\"Saved {asset_name}_{timespan}.csv\")\n",
    "\n",
    "# Example usage\n",
    "assets = [\n",
    "    # # Forex Currency Pairs\n",
    "    \"C:EURUSD\", \"C:USDJPY\", \"C:GBPUSD\", \"C:AUDUSD\", \"C:USDCHF\",\n",
    "    \"C:USDCAD\", \"C:NZDUSD\", \"C:EURGBP\", \"C:EURJPY\", \"C:GBPJPY\",\n",
    "    \"C:AUDJPY\", \"C:EURAUD\", \"C:CHFJPY\", \"C:EURCAD\", \"C:GBPCAD\",\n",
    "    \"C:AUDCAD\", \"C:NZDJPY\", \"C:GBPCHF\", \"C:EURCHF\", \"C:USDSGD\",\n",
    "\n",
    "    # # Commodities\n",
    "    \"C:XAUUSD\", \"C:XAGUSD\",\n",
    "\n",
    "    # # Cryptocurrencies\n",
    "    \"X:BTCUSD\", \"X:ETHUSD\", \"X:LTCUSD\", \"X:XRPUSD\",\n",
    "\n",
    "    # # Indices\n",
    "    \"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\"\n",
    "]\n",
    "\n",
    "fetch_data_for_assets(assets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
